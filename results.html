
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

<title>SpaceTx: experimental and computational methods compartison for spatially resolved transcriptomics</title>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Assistant:wght@200;400;600;700&display=swap" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>
  <nav id="main-navbar" class="navbar navbar-expand-lg navbar-light">
    <div class="container pt-2 pb-4">
      <a class="navbar-brand" href="index.html"><img id="main-logo" src="/_static/spacetx_logo_web_black.svg"></a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
    </div>
    <div id="main-menubar" class="container-fluid">
      <div class="container position-relative">
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav me-auto mb-2 mb-lg-0 justify-content-between">
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
                About
              </a>
              <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
                <li><a class="dropdown-item" href="about.html">SpaceTx</a></li>
                <li><a class="dropdown-item" href="people.html">People</a></li>
                <li><a class="dropdown-item" href="spacejam.html">SpaceJam Hackathon</a></li>
              </ul>
            </li>
            <li><a class="nav-link" href="data.html">Data</a></li>
            <li><a class="nav-link" href="#">Results and Analysis</a></li>
            <li><a class="nav-link" href="publications.html">Publications</a></li>
            <li><a class="nav-link" href="contribute.html">Contributing Guidelines</a></li>
          </ul>
          <form class="d-flex mb-4" id="main-search" action="search.html" method="get">
            <input class="form-control form-control-sm me-2" type="search" placeholder="Search" aria-label="Search" name="q">
            <button class="btn btn-success btn-sm" type="submit">Search</button>
          </form>
        </div>
      </div>
    </div>
  </nav>

    <div id="wrapper">
      <div id="main" class="container">
        <div class="sidebar">
        </div>
        <div id="content">
          
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="consensus-taxonomy-and-marker-genes">
<h1>Consensus Taxonomy and Marker Genes<a class="headerlink" href="#consensus-taxonomy-and-marker-genes" title="Permalink to this heading">¶</a></h1>
<section id="cell-type-identification-in-single-cell-rnaseq-data">
<h2>Cell Type Identification in single cell RNASeq data<a class="headerlink" href="#cell-type-identification-in-single-cell-rnaseq-data" title="Permalink to this heading">¶</a></h2>
<p>The SpaceTx consortium chose the mouse visual cortex as the substrate for spatial transcriptomics comparisons. This was Consensus clustering</p>
<p>Computational strategies:</p>
<ul class="simple">
<li><p>(Eeshit DV) SIMLR (Single-cell Interpretation via Multi-kernel LeaRning) learns an appropriate distance metric for clustering and accounts for drop-outs.  Can also be run as a consensus clustering strategy. (<a class="reference external" href="https://github.com/BatzoglouLabSU/SIMLR">https://github.com/BatzoglouLabSU/SIMLR</a>).</p></li>
<li><p>(Peter K) PAGODA (Pathway And Gene set Over-Dispersion Analysis) resolves multiple aspects of gene expression heterogeneity by testing gene sets for coordinated variability among measured cells                                                                             (<a class="reference external" href="http://hms-dbmi.github.io/scde/pagoda.html">http://hms-dbmi.github.io/scde/pagoda.html</a>).</p></li>
<li><p>(Zizhen Y) scrattch.hicat (Hierarchical, Iterative Clustering for Analysis of Transcriptomics) iteratively repeats a multi-step approach on each cluster using different variable genes until no new clusters can be defined, then bootstraps the iterative process (<a class="reference external" href="https://github.com/AllenInstitute/scrattch.hicat">https://github.com/AllenInstitute/scrattch.hicat</a>).</p></li>
<li><p>(Trygve B) - Precursor pipeline used for human MTG</p></li>
<li><p>(Kenneth H) proMMT (Probabilistic Mixture Modeling for Transcriptomics) uses an EM algorithm to iteratively define clusters using the Bayesian information criterion and identify a sparse set of genes varying across clusters (Harris et al 2018; “Classes and continua…”; PLoS Biol.).</p></li>
</ul>
<p>Most methods were run multiple times with different parameter settings.</p>
<p>Cluster consensus:</p>
<ul class="simple">
<li><p>(Trygve B) - Cluster comparisons using Adjusted Rand, VI, etc. and showing which clusters subclasses /types are split more by various methods</p></li>
<li><p>(Brian A) - Consensus mouse and human clusters were defined using clusterExperiment R library, which clusters the co-occurrence matrix (<a class="reference external" href="https://github.com/epurdom/clusterExperiment">https://github.com/epurdom/clusterExperiment</a>).</p></li>
</ul>
<p>Mouse clusters were defined on VISp + ALM data set and 68 ALM-specific clusters were removed from the consensus clustering, for 191 total clusters</p>
</section>
<section id="marker-gene-selection">
<h2>Marker Gene Selection<a class="headerlink" href="#marker-gene-selection" title="Permalink to this heading">¶</a></h2>
<p>Four different computational strategies:</p>
<ul class="simple">
<li><p>(Jeremy M) - Greedy algorithm generally identifies combinatorial genes.  This method was used for completing smaller panels and validating all panels.</p></li>
<li><p>(Kenneth H) Probability model aimed to maximize the average number of levels of a clustering tree correctly classified</p></li>
<li><p>(Brian A) - NS-Forest: Random forest strategy aimed at identifying the most informative markers of specific cell types</p></li>
<li><p>(Eeshit DV) Random forest strategy which ranks genes based on the overall importance towards classification</p></li>
</ul>
<p>(Eeshit DV) These methods were merged together into a ranked list and some gene panels were selected from this list.</p>
</section>
</section>
<section id="segmentation-and-cell-type-mapping">
<h1>Segmentation and Cell Type Mapping<a class="headerlink" href="#segmentation-and-cell-type-mapping" title="Permalink to this heading">¶</a></h1>
<section id="cell-segmentation">
<h2>Cell Segmentation<a class="headerlink" href="#cell-segmentation" title="Permalink to this heading">¶</a></h2>
<p>Cell segmentation associates mRNA spot locations with individual cells, creating transcriptomic profiles that make up the cell-by-gene table.</p>
<p><strong>SpaceTx Cell Segmentation Pipeline</strong></p>
<ol class="arabic simple">
<li><p>Feature-based nucleus segmentation based on DAPI is applied to stitched 2D volumes and consists of two steps: (i) foreground segmentation and (ii) its consecutive splitting into separate instances (nuclei).
For the first task, simple thresholding, either by employing one of the many available thresholding methods or by fine-tuning the cutoff intensity value, was sufficient to segment the foreground in all the available data sets.
Splitting of the foreground into separate instances is performed per connected component, which allows efficient parallelizable implementation of our method.
Based on the observation that most nuclei have rather regular elliptical shape, we developed an approach inspired by the work of Bilgin et al. [1] than employs elliptic features to extract two types of information:
(i) curvature maps whose local minima correspond to locations of separation lines between touching nuclei and (ii) markers cognitively describing shapes of the nuclei and defined as the regions with positive Gaussian curvature and negative mean curvature.
Calculation of the curvature maps and the markers is guided by a scale parameter, one for each, the value of which is chosen experimentally based on the average nucleus size.
The markers are consecutively turned into super-pixels by performing skeletonization on the foreground with subtracted markers region. Calculated super-pixels are progressively merged based on the
inter-pixel similarity score for obtaining the final segmentation. The similarity between two neighbouring super-pixels is defined based on the average value of the curvature map in the region between
the corresponding markers and is recalculated after each merging iteration. This process stops after the maximum value of the inter-pixel similarity does not exceed the predefined threshold
(whose value was kept fixed for all the test data sets). The described algorithm that worked equally well on the entire variety of SpaceTX data, including DAPI channels of the fluorescence microscopy data as well as 10x Visium histopathology images.</p></li>
<li><p>Augmented Cell Segmentation using Baysor. Using the nuclear segementation as a prior for cell location, Baysor assigned mRNA spots to cells probabilistically, including cell size and gene composition.</p></li>
</ol>
</section>
<section id="cell-type-mapping-methods">
<h2>Cell Type Mapping Methods<a class="headerlink" href="#cell-type-mapping-methods" title="Permalink to this heading">¶</a></h2>
<p>This is the first time spatial transcriptomics data has been analyzed and compared across methods for cell type determination. We developed approaches to combine multiple cell type mapping methods and applied them to data sets from five experimental methods.</p>
<p>A primary output of segmentation in each of the image-based experimental methods is a table of putative cells which each have a count of the number of molecules per gene as well as a soma location.  Cells located outside of the primary visual cortex (VISp) based on expert annotation or that do not pass quality control filters are excluded from further analysis.</p>
<blockquote>
<div><p>We next aimed to assign a cell type and associated confidence to each putative cell based on gene molecule counts.  This was done using a combined analysis approach, where the strategies below were used to map cells to cell types from the taxonomy defined for SpaceTx, and the results of these strategies were then combined to produce a single combined cell type call with associated confidence score for each remaining cell.</p>
</div></blockquote>
<ul class="simple">
<li><p>Annotation of VISp area for mapping
Cell locations were visualized in Napari <a class="reference external" href="https://napari.org">https://napari.org</a> and manually
annotated to contain the largest possible area of primary visual cortex.
Layers were manually annotated based on cell density and gene expression.</p></li>
</ul>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://jcventerinstitute.github.io/celligrate/">FR-Match cell2cluster</a> <a class="reference external" href="https://github.com/yunzhang813/SpaceTx-cell-type-calling">[results]</a> [example code]</p></li>
<li><p><a class="reference external" href="https://github.com/acycliq/pciSeq">pciSEQ</a> [results] [example code]</p></li>
<li><p><a class="reference external" href="https://github.com/AllenInstitute/mfishtools/">mFISHtools</a> [results] [example code]</p></li>
<li><p><a class="reference external" href="https://github.com/kharchenkolab/Baysor">Baysor</a> [results] [example code]</p></li>
<li><p><a class="reference external" href="https://github.com/broadinstitute/Tangram">Tangram</a> [results] [example code]</p></li>
</ol>
</section>
<section id="cell-type-mapping-consensus">
<h2>Cell Type Mapping Consensus<a class="headerlink" href="#cell-type-mapping-consensus" title="Permalink to this heading">¶</a></h2>
<p>The SpaceTx cell type mapping strategies and combination of these results into consensus mapping results are described in detail in <a class="reference external" href="https://doi.org/10.1101/2022.03.28.486139">Reference-based cell type matching of spatial transcriptomics data</a>.</p>
<p><em>summary Figure coming soon</em></p>
</section>
<section id="visium-data-single-cell-mapping">
<h2>Visium Data Single Cell Mapping<a class="headerlink" href="#visium-data-single-cell-mapping" title="Permalink to this heading">¶</a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Visium is often described as unbiased and transcriptome-wide, since it’s not based on a priori selection of genes to be examined and targets all poly-adenlated transcripts. However, the current Visium platform does not provide single cell resolution and, though dependent on tissue, the common estimate is that approximately 1-10 cells contribute to the observed gene expression at each spot. The “mini-bulk” property of spots means that spots rarely can be assigned to a single cell type, and more common is to characterize these w.r.t. cell type compositions (e.g., proportion of cell types present at each location). For such purposes, several methods where single cell/nuclei data is used as a guide reference have been proposed, with the shared objective of decomposing the joint expression profiles observed in a spot into contributions from the cell types defined in the single cell/nuclei data.</p></li>
<li><p><strong>stereoscope</strong> and <strong>Tangram</strong> were used to deconvolve the spatial Visium data using non-spatial single cell data, a procedure we refer to as “mapping” of the latter onto the former. In short, once presented with the Visium data, both these approaches will provide a proportion estimate of each cell type within every spot, thus allowing the spatial distribution of each cell type to be charted. Although the final products are similar, the two methods differ substantially in design; stereoscope relying on a probabilistic framework where both data modalities are modelled with a negative binomial distribution, while Tangram cast the the task more as a optimization problem where a map between single cells and spatial locations.</p></li>
<li><p>For consistency, the cell type mapping analysis focuses on the small region that constitutes the VISp as shown in Figure 1; even though spatial gene expression data was generated from a larger part of the tissues (about half of a coronal mouse brain section fit onto the capture area). We aim to evaluate the mapping from each method, as well as comparing these two to each other. Nevertheless, establishing a ground truth for the proportion values is arguably even harder than for the cell type identities in the image-based methods, hence concurrence with well-known locations of cell types (e.g., Layer associated) will serve as the basis of our evaluation.</p></li>
</ul>
</div></blockquote>
<a class="reference internal image-reference" href="_images/visium.png"><img alt="_images/visium.png" src="_images/visium.png" style="width: 100%;" /></a>
<p><strong>Figure 1</strong>. A) zoom in on the regions of interests. Spots included in the analysis are marked on the tissue with black circles. The tissue edged to which distance is measured is indicated by a dashed red line. B) Pearson correlation values between cell type proportion estimates from stereoscope and Tangram. The star (*) on Meis2 indicates that this correlation did not have a significant p-value. C) Smoothed curves (loess smoothing) of the cell type proportions when plotted as a function of distance to the tissue edge (red in A).</p>
<blockquote>
<div><ul class="simple">
<li><p>By computing the correlation (Pearsons’s r) between proportion estimates for each cell type it’s possible to quantitatively assess how results from the two methods relate. A  significant positive correlation between the proportion estimates could be observed for all cell types except Meis2, where the correlation was negative but also non-significant (p = 0.36), see Figure 1B.  High correlation values were observed for several of the layer types as well as Macrophages and Astrocytes. Most of the cell types with poor correlation were - according to the proportion estimates - lowly abundant in the tissue, implying mapping of rare cell types likely are more challenging to map and the result associated with higher uncertainty.</p></li>
<li><p>Next, we were interested in how the different layer cell types were distributed along the axis orthogonal to the tissue edge, i.e., when travelling further into the tissue (blue arrow Figure 1A). We thus measured the shortest distance for every spot to the tissue edge and modelled the cell type proportion values as a function of this distance, loess (locally estimated scatterplot smoothing) curve smoothing was used to get a more continuous graph, and to better capture the general trends in the data, see Methods. The two methods by en large agreed; albeit not always unimodal, the cell type distributions had one dominant major mode - overlapping well across methods - and exhibited the expected right shift trend (layer types with higher numbers being more prevalent deeper into the cortex and vice versa), see Figure 1C. For some cell types, the distributions were multimodal indicating potential “mismapping”, still in the cases where both methods independently located these peaks at almost identical positions the explanation might be biological or experimental.</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="software-data-visualization-and-example-notebooks">
<h1>Software, Data Visualization and Example Notebooks<a class="headerlink" href="#software-data-visualization-and-example-notebooks" title="Permalink to this heading">¶</a></h1>
<section id="data-formatting-standards-and-computational-pipelines">
<h2>Data Formatting Standards and Computational Pipelines<a class="headerlink" href="#data-formatting-standards-and-computational-pipelines" title="Permalink to this heading">¶</a></h2>
<p>Many Spatial Transcriptomics methods are based on a common pattern of data acquisition: images are collected in multiple fluorescence channels after a round of readout chemistry, and this process is repeated until all fluorescent readouts have been imaged.  Similarly, the compuational processing pipelines to turn raw images into transcriptional profiles of cells share many computational steps. In this context, the SpaceTx Consortium pursued two software projects:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spacetx-starfish.readthedocs.io/en/latest/help_and_reference/spacetx-format/SpaceTxFormat/index.html#sptx-format">SpaceTx-Format</a> is a fully-specified format for image-based spatial transcriptomics raw data, including spatial structure of images in 3D, description of round-channel organization and a specification for the “codebook” relating fluorescence images to gene identity.</p></li>
<li><p><a class="reference external" href="https://spacetx-starfish.readthedocs.io/en/latest/index.html">starfish</a> is a Python package that provides processing modules that can be assembled into completel processing pipelines to extract mRNA locations for barcode methods (MERFISH, SEQFISH), sequencing-based readouts (ISS, FISSEQ) and non-barcoded readouts (osmFISH).</p></li>
</ul>
<p>Both of these projects are housed in the <a class="reference external" href="https://github.com/spacetx/starfish">starfish github repo</a> and can be cited using the <a class="reference external" href="https://joss.theoj.org/papers/10.21105/joss.02440">starfish article in Journal of Open Source Software</a>.</p>
</section>
<section id="data-visualization">
<h2>Data Visualization<a class="headerlink" href="#data-visualization" title="Permalink to this heading">¶</a></h2>
<p>Spatial Transcriptomics data presents unique challenges for visualization.</p>
<ul>
<li><dl class="simple">
<dt>Visualization of processed spatial transcriptomics data</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Processed Spatial Transcriptomics data typically includes:</dt><dd><ul>
<li><p>Spot Tables: Spatial locations for all mRNA spots detected in the experiment.</p></li>
<li><p>Cell by Gene Tables: Cell locations and the total mRNA counts associated with each cell.</p></li>
<li><p>Overview Image: spatial context for high-resolution data. For example, SpaceTx Consortium data includes high resolution data of mouse VISp and the overview image includes a DAPI image of the entire coronal section containing the VISp data.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<ul>
<li><dl class="simple">
<dt>Cell by Gene Visualization in Cytosplore</dt><dd><ul class="simple">
<li><p>Boudewijn Lelieveldt and the Cytosplore Team have created a project-specific Cytosplore viewer for interactive exploration of SpaceTx cell by gene data</p></li>
<li><p>download link:</p></li>
<li><p>walk-through or screenshot</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt>Segmentation-free data analysis and visualization</dt><dd><ul class="simple">
<li><p>The heterogeneity of gene expression in tissue can be explored without cell segmentation.</p></li>
<li><p>The SSAM method (<a class="reference external" href="https://www.nature.com/articles/s41467-021-23807-4">Nature Communications volume 12, Article number: 3545 (2021)</a>) applied to SpaceTx data creates an easily visualized landscape of gene expression that can highlight rare cell types or tissue organization.</p></li>
</ul>
<blockquote>
<div><a class="reference internal image-reference" href="_images/ssam-spacetx.png"><img alt="_images/ssam-spacetx.png" src="_images/ssam-spacetx.png" style="width: 800px;" /></a>
</div></blockquote>
</dd>
</dl>
</li>
</ul>
</li>
<li><dl class="simple">
<dt>Image Data Visualization</dt><dd><ul class="simple">
<li><p>Unlike traditional biological imaging, spatial transcriptomics image data is often uninterpretible on its own. For example, each (round,channel) image from a MERFISH experiment typically contains diffraction-limited spots from all copies of 10s of different mRNA species. However, an image of DAPI from the same experiment could be very useful for visualizing tissue context for processed spatial transcriptomics data.</p></li>
<li><p>Raw image data for spatial transcriptomics is frequently at the terabyte scale and visualization requires comprehension of the spatial and (round,channel) organization of the images.</p></li>
<li><p>Modern bioimage visualization tools such as <a class="reference external" href="https://github.com/google/neuroglancer">Neuroglancer</a> and <a class="reference external" href="https://napari.org/">Napari</a> can be used to visualize spatial transcriptomics image data, but only to the extent that image data format information is interpretable by the visualization tool. Visualization tools will become more interoperable when and if the bioimaging community converges on formats and metadata standards for multiround fluorescence experiments. Large community standards projects like  <a class="reference external" href="https://forum.image.sc/tag/ome-ngff">OME-NGFF</a> as well as smaller, nascent projects like <a class="reference external" href="https://github.com/tlambert03/useq-schema">useq-schema</a> could form the basis of a metadata standard that could be applied to spatial transcriptomics microscopy data to simplify interactive visualization of large scale image data.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="r-markdowns-jupyter-notebooks-scripts">
<h2>R Markdowns / Jupyter Notebooks &amp; Scripts<a class="headerlink" href="#r-markdowns-jupyter-notebooks-scripts" title="Permalink to this heading">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="results/human-clustering_notebook.html">CZI Human : Dimensionality Reduction and Clustering with SIMLR</a></li>
<li class="toctree-l1"><a class="reference internal" href="results/mouse-clustering_notebook.html">CZI Mouse : Dimensionality Reduction and Clustering with SIMLR</a></li>
<li class="toctree-l1"><a class="reference external" href="https://spacetx.github.io/_static/consensus_clustering.py">Script for consensus clustering (GMCS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="results/rmd1.celltype_calling_frmatch.html">Cell type calling for spatial transcriptomics (spaceTx) data - smFISH and scRNAseq</a></li>
<li class="toctree-l1"><a class="reference internal" href="results/nb1.consensus_msmfish.html">SSAM Notebook: Multiplexed smFISH data SSAM analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="results/nb2.consensus_merfish.html">SSAM Notebook: (Allen) MERFISH data SSAM analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="results/nb3.consensus_baristaseq.html">SSAM Notebook: BaristaSeq data SSAM analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="results/nb4.consensus_exseq.html">SSAM Notebook: ExSeq data SSAM analysis</a></li>
</ul>
</div>
</section>
<section id="software-packages">
<h2>Software Packages<a class="headerlink" href="#software-packages" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/kharchenkolab/Baysor">Baysor</a></p></li>
<li><p><a class="reference external" href="https://github.com/JCVenterInstitute/FRmatch">FR-Match</a></p></li>
<li><p><a class="reference external" href="https://github.com/AllenInstitute/scrattch.hicat">map.cells*</a></p></li>
<li><p><a class="reference external" href="https://github.com/AllenInstitute/mfishtools">mfishtools</a></p></li>
<li><p><a class="reference external" href="https://github.com/acycliq/pciSeq">pciSeq</a></p></li>
<li><p><a class="reference external" href="https://github.com/broadinstitute/Tangram">Tangram</a></p></li>
<li><p><a class="reference external" href="https://github.com/HiDiHlabs/ssam">SSAM</a></p></li>
<li><p><a class="reference external" href="https://viewer.cytosplore.org">Cytosplore Viewer</a></p></li>
</ul>
<script src="/_static/sidebar.js"></script>
<link rel="stylesheet" href="/_static/sidebar.css"></section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
        </div>
      </div>
    </div>

  <div id="footer">
    <p class="copyright">
      © 2022 SpaceTx consortium<br>
    </p>
  </div>

  </body>
</html>